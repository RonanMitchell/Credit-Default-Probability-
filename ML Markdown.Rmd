---
title: "Predicting Credit Default"
author: "Ronan Morris"
date: "2023-06-26"
output:
  pdf_document: 
    latex_engine: xelatex
header-includes:
  - \usepackage{ragged2e}
  - \usepackage{titlesec}
  - \titleformat*{\section}{\fontsize{12}{14}\bfseries}
  - \titleformat*{\subsection}{\fontsize{12}{14}\itshape}
   -0 \setlength{\spaceskip}{1.5\fontdimen2\font}
  - \usepackage{fontspec}
  - \setmainfont{Times New Roman}
  - \justifying
---

```{r Setup, include = FALSE}

tinytex::install_tinytex(force = TRUE)
options(repos = "https://cran.mirror.ac.za/")

#Installing Packages 

install.packages("caret")
install.packages("tidyverse")
install.packages("ggplot2")
install.packages("randomForest")
install.packages("glmnet")

```

```{r Data Design, include = FALSE}

rm(list = ls())

Data <- read.csv("Data/Credit Default Dataset.csv")
Data <- na.omit(Data)

Data$Gender <- gsub("2", "0", Data$Gender) # 0 == Female 

Data$Education <- gsub("3|4|5|6", "0", Data$Education) 
    Data$Education <- gsub("2|1", "1", Data$Education) # Uni+ == 1

Data$Marriage.Status <- gsub("2|3", "0", Data$Marriage.Status) 

Data$Quality <- (Data[, 6] + 
                Data[, 7] + 
                Data[, 8] +
                Data[, 9] +
                Data[, 10] +
                Data[, 11]) # Only for regressions, not ML.  

Data <- as.data.frame(lapply(Data, as.numeric))

Standardised <- c(1, 5, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23)

Process <- function(a, b) {
  b[, a] <- scale(b[, a])
  NewData <<- b
} # might want to do again later.

Process(Standardised, Data) # Standardised Data
rm(Standardised)

# All monetary sums have been standardised (subtract mean and divide by standard deviation) 
# Must undo this when substituting in values.

NewData <- NewData[,-25]

# All variables now range between -2 and 2. Most are around 1. Comparison is fine!

```

```{r Feautre Selection, include=FALSE}

library(glmnet)



```


```{r ML Model, include=FALSE}

library(caret)

set.seed(123)  
Training <- createDataPartition(NewData$Default..Outcome., p = 0.7, list = FALSE)
Train <- Data[Training, ]
Test <- Data[-Training, ]

###
library(randomForest)

MLModel <- randomForest(Default..Outcome. ~ ., data = Train, ntree = 200)

###

Predict <- predict(MLModel, newdata = Test)
Predict <- ifelse(Predict >= 0.5, 1, 0)

Success <- sum(Predict[Test$Default..Outcome. == 1] == 1) / sum(Test$Default..Outcome. == 1)

Fail <- sum(Predict[Test$Default..Outcome. == 0] == 0) / sum(Test$Default..Outcome. == 0)

print(c(Success, Fail))

# Current Stage: very bad. Only predicts 37% of defaults. Very very bad man.

```

